So that algorithm would get me to the solution so much faster. And we can appreciate this even if we just look at some of the numbers, ultimately, as follows. So if I start with, say, 1,024 pages total in the phone book, and I'm looking for Mike Smith, and I divide and conquer this problem, splitting the problem in half and in half and in half, I go to 512, I go to 256, 128, 64, 32, 16, eight, four, two, and one. After just 10 steps, I have found Mike Smith's page. By contrast, that first algorithm where I just did one page at a time, how many steps, maybe, might it have taken me to find Mike Smith? Yeah, like, 700, 800, roughly where the S's might be. So in the worst case, 1,000 pages, if I look through the whole thing. The second algorithm, maybe, 500 pages because I'm going twice at a time. But my God, 10 steps with this algorithm here. And odds are that would be the algorithm most of us in this room would reach for by default, which is to say that a lot of problem solving really, as we'll find, is just about harnessing your existing intuition and comfort with ideas that now you just need to translate in such a way that machines and other humans can understand. So how might we just think about how much better that algorithm is? Well, consider this first line here. On this y-axis, or vertical axis, let me describe this as the time to solve some problem. And on the horizontal, or x-axis, the size of the problem. So the number of pages in the phone book would get bigger as you go to the right and the number of seconds or page turns required would go up along the y-axis here. So that first algorithm, depicted here in red, suggests a one-to-one relationship between the number of pages in the book and the number of seconds to find someone. So you have this straight line. A slope of 1 over 1, if you will. And so if we consider the second algorithm, the second algorithm is also going to be a straight line, but that straight line is going to be lower on the graph. Why? Because for any size problem, it's going to take me half as much time to search that phone book because, of course, I'm going two pages at a time. So if we see this, for instance, if this dashed line represents some number of pages in the phone book, maybe 1,024, well, you can see that it might take this many seconds or page turns to actually find Mike Smith with that second algorithm. But in the first algorithm, that same number of pages would take way more time to solve, literally twice as much time in this case. Well what about the third algorithm? Well, even if your memory of what a logarithm is a little hazy, it just describes a fundamentally different shape. The green line describes that third and final algorithm whereby you divided the problem not one page at a time or two pages at a time, but 50% again and again and again. You have it again and again and again. And notice that as the number of pages in the phone book gets really large, you barely make an impact on how much time it takes to solve that problem. For instance, if Cambridge and Allston, two towns here in Massachusetts, merge next year and their phone books become one phone book that's twice as big, so not 1,000 pages each, but 2000 pages total, how many more steps might it take us to find Mike Smith in next year's phone book if it's got 2000 pages instead of 1,000? Just one more step. But the first two algorithms, that's another 1,000 steps, maybe, or another 500. These are fundamentally big differences in efficiency, so to speak. So let's translate this idea, this intuition, into the first example of code.
